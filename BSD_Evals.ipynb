{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BSD_Evals\n",
        "An LLM evaluation framework by Brett DiDonato\n",
        "\n",
        "Project repo: https://github.com/brettdidonato/BSD_Evals\n",
        "\n",
        "This project enables the creation of your own LLM evaluation framework against popular LLM providers (Anthropic, Google, OpenAI) and cloud providers (Google Cloud). See evals/test_evals.json for an example on how to build your own set of evaluations and test.py for execution. Update config.ini before running to enable APIs and services as needed."
      ],
      "metadata": {
        "id": "kbcoocm7dsoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone github repo and move to top directory\n",
        "\n"
      ],
      "metadata": {
        "id": "aMouKtMtdpJW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXoeHMKNa6ys",
        "outputId": "0d755314-f5bd-4690-cf85-63c8546eab67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BSD_Evals'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/27)\u001b[K\rremote: Counting objects:   7% (2/27)\u001b[K\rremote: Counting objects:  11% (3/27)\u001b[K\rremote: Counting objects:  14% (4/27)\u001b[K\rremote: Counting objects:  18% (5/27)\u001b[K\rremote: Counting objects:  22% (6/27)\u001b[K\rremote: Counting objects:  25% (7/27)\u001b[K\rremote: Counting objects:  29% (8/27)\u001b[K\rremote: Counting objects:  33% (9/27)\u001b[K\rremote: Counting objects:  37% (10/27)\u001b[K\rremote: Counting objects:  40% (11/27)\u001b[K\rremote: Counting objects:  44% (12/27)\u001b[K\rremote: Counting objects:  48% (13/27)\u001b[K\rremote: Counting objects:  51% (14/27)\u001b[K\rremote: Counting objects:  55% (15/27)\u001b[K\rremote: Counting objects:  59% (16/27)\u001b[K\rremote: Counting objects:  62% (17/27)\u001b[K\rremote: Counting objects:  66% (18/27)\u001b[K\rremote: Counting objects:  70% (19/27)\u001b[K\rremote: Counting objects:  74% (20/27)\u001b[K\rremote: Counting objects:  77% (21/27)\u001b[K\rremote: Counting objects:  81% (22/27)\u001b[K\rremote: Counting objects:  85% (23/27)\u001b[K\rremote: Counting objects:  88% (24/27)\u001b[K\rremote: Counting objects:  92% (25/27)\u001b[K\rremote: Counting objects:  96% (26/27)\u001b[K\rremote: Counting objects: 100% (27/27)\u001b[K\rremote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects:   5% (1/20)\u001b[K\rremote: Compressing objects:  10% (2/20)\u001b[K\rremote: Compressing objects:  15% (3/20)\u001b[K\rremote: Compressing objects:  20% (4/20)\u001b[K\rremote: Compressing objects:  25% (5/20)\u001b[K\rremote: Compressing objects:  30% (6/20)\u001b[K\rremote: Compressing objects:  35% (7/20)\u001b[K\rremote: Compressing objects:  40% (8/20)\u001b[K\rremote: Compressing objects:  45% (9/20)\u001b[K\rremote: Compressing objects:  50% (10/20)\u001b[K\rremote: Compressing objects:  55% (11/20)\u001b[K\rremote: Compressing objects:  60% (12/20)\u001b[K\rremote: Compressing objects:  65% (13/20)\u001b[K\rremote: Compressing objects:  70% (14/20)\u001b[K\rremote: Compressing objects:  75% (15/20)\u001b[K\rremote: Compressing objects:  80% (16/20)\u001b[K\rremote: Compressing objects:  85% (17/20)\u001b[K\rremote: Compressing objects:  90% (18/20)\u001b[K\rremote: Compressing objects:  95% (19/20)\u001b[K\rremote: Compressing objects: 100% (20/20)\u001b[K\rremote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 27 (delta 6), reused 23 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects:   3% (1/27)\rReceiving objects:   7% (2/27)\rReceiving objects:  11% (3/27)\rReceiving objects:  14% (4/27)\rReceiving objects:  18% (5/27)\rReceiving objects:  22% (6/27)\rReceiving objects:  25% (7/27)\rReceiving objects:  29% (8/27)\rReceiving objects:  33% (9/27)\rReceiving objects:  37% (10/27)\rReceiving objects:  40% (11/27)\rReceiving objects:  44% (12/27)\rReceiving objects:  48% (13/27)\rReceiving objects:  51% (14/27)\rReceiving objects:  55% (15/27)\rReceiving objects:  59% (16/27)\rReceiving objects:  62% (17/27)\rReceiving objects:  66% (18/27)\rReceiving objects:  70% (19/27)\rReceiving objects:  74% (20/27)\rReceiving objects:  77% (21/27)\rReceiving objects:  81% (22/27)\rReceiving objects:  85% (23/27)\rReceiving objects:  88% (24/27)\rReceiving objects:  92% (25/27)\rReceiving objects:  96% (26/27)\rReceiving objects: 100% (27/27)\rReceiving objects: 100% (27/27), 16.31 KiB | 8.16 MiB/s, done.\n",
            "Resolving deltas:   0% (0/6)\rResolving deltas:  16% (1/6)\rResolving deltas:  33% (2/6)\rResolving deltas:  50% (3/6)\rResolving deltas:  66% (4/6)\rResolving deltas:  83% (5/6)\rResolving deltas: 100% (6/6)\rResolving deltas: 100% (6/6), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/brettdidonato/BSD_Evals.git\n",
        "!mv -v BSD_Evals/* ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install libraries"
      ],
      "metadata": {
        "id": "VFYvUOmUdhAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "vCyyEHKVdfRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google authentication"
      ],
      "metadata": {
        "id": "DgVoMqfYeBBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "Yjd86IaebE8q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***IMPORTANT: Update config.ini with your credentials before running!***\n",
        "\n",
        "Run evaluations for all models."
      ],
      "metadata": {
        "id": "AAJySBcleEK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bsd_evals import BSD_Evals\n",
        "from eval import Eval\n",
        "from model import Model\n",
        "\n",
        "'''\n",
        "Define your models family and version. Other fields optional.\n",
        "\n",
        "Check latest model versions:\n",
        "Anthropic: https://docs.anthropic.com/claude/docs/models-overview#model-recommendations\n",
        "Google Cloud Vertex AI: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versioning\n",
        "Google AI Studio: https://ai.google.dev/models/gemini\n",
        "OpenAI: https://platform.openai.com/docs/models/overview\n",
        "'''\n",
        "models = [\n",
        "    Model(\n",
        "        model_family=\"Claude\",\n",
        "        model_version=\"claude-3-haiku-20240307\",\n",
        "        service=\"Anthropic\",\n",
        "        max_tokens=4096,\n",
        "        temperature=1.0),\n",
        "    Model(\n",
        "        model_family=\"Claude\",\n",
        "        model_version=\"claude-3-sonnet-20240229\",\n",
        "        service=\"Anthropic\",\n",
        "        max_tokens=4096,\n",
        "        temperature=1.0),\n",
        "    Model(\n",
        "        model_family=\"Claude\",\n",
        "        model_version=\"claude-3-opus-20240229\",\n",
        "        service=\"Anthropic\",\n",
        "        max_tokens=4096,\n",
        "        temperature=1.0),\n",
        "    Model(\n",
        "        model_family=\"Gemini\",\n",
        "        model_version=\"gemini-1.0-pro\",\n",
        "        service=\"Google AI Studio\",\n",
        "        max_output_tokens=2048),\n",
        "    Model(\n",
        "        model_family=\"Gemini\",\n",
        "        model_version=\"gemini-1.0-pro-001\",\n",
        "        service=\"Google Cloud\",\n",
        "        max_output_tokens=2048,\n",
        "        temperature=0.8,\n",
        "        top_k=40,\n",
        "        top_p=1),\n",
        "    Model(\n",
        "        model_family=\"GPT\",\n",
        "        model_version=\"gpt-3.5-turbo\",\n",
        "        service=\"Open AI\",\n",
        "        temperature=1.0),\n",
        "    Model(\n",
        "        model_family=\"GPT\",\n",
        "        model_version=\"gpt-4-turbo-preview\",\n",
        "        service=\"Open AI\",\n",
        "        temperature=1.0),\n",
        "    Model(\n",
        "        model_family=\"GPT\",\n",
        "        model_version=\"gpt-4\",\n",
        "        service=\"Open AI\",\n",
        "        temperature=1.0)\n",
        "]\n",
        "\n",
        "evals = BSD_Evals(models=models, test_eval_file=\"./evals/test_evals.json\")\n",
        "evals.run()\n",
        "evals.display_results(\"html\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lkvXrttTbyma",
        "outputId": "285baa2a-259d-4e89-a246-13f62c03cce0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing 6 evals across 8 models => 48 total evals.\n",
            "\n",
            "**********************************\n",
            "Evaluation #1\n",
            "Evaluation description: Basic math\n",
            "Evaluation prompt: 1+2=\n",
            "Expected response: 3\n",
            "Evaluation type: perfect_exact_match\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-haiku-20240307', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: 3\n",
            "runtime: 0.7846758365631104\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-sonnet-20240229', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: 1 + 2 = 3\n",
            "runtime: 0.6912224292755127\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-opus-20240229', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: 1 + 2 = 3\n",
            "\n",
            "In mathematics, when you add two numbers together, the result is called the sum. In this case, the sum of 1 and 2 is 3.\n",
            "\n",
            "This is a simple example of addition, one of the four basic arithmetic operations along with subtraction, multiplication, and division. Addition is the process of combining two or more numbers to get a larger number.\n",
            "runtime: 4.338898420333862\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='Gemini', model_version='gemini-1.0-pro', service='Google AI Studio' max_output_tokens=2048)\n",
            "3\n",
            "Model response: 3\n",
            "runtime: 1.3453481197357178\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='Gemini', model_version='gemini-1.0-pro-001', service='Google Cloud' max_output_tokens=2048, temperature=0.8, top_k=40, top_p=1)\n",
            "Model response: 3\n",
            "runtime: 0.7152316570281982\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-3.5-turbo', service='Open AI' temperature=1.0)\n",
            "Model response: 3\n",
            "runtime: 0.32065463066101074\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-4-turbo-preview', service='Open AI' temperature=1.0)\n",
            "Model response: 1 + 2 = 3\n",
            "runtime: 1.0801301002502441\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-4', service='Open AI' temperature=1.0)\n",
            "Model response: 3\n",
            "runtime: 0.6962935924530029\n",
            "Evaluation passed.\n",
            "\n",
            "**********************************\n",
            "Evaluation #2\n",
            "Evaluation description: Basic stats\n",
            "Evaluation prompt: I have two red balls and two blue balls. You take one blue ball away. How many balls do I have left? Just provide a numeric digit response (no text).\n",
            "Expected response: 3\n",
            "Evaluation type: perfect_exact_match\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-haiku-20240307', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: 3\n",
            "runtime: 0.6032462120056152\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-sonnet-20240229', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: 3\n",
            "runtime: 0.6559829711914062\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-opus-20240229', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: 3\n",
            "runtime: 1.68210768699646\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='Gemini', model_version='gemini-1.0-pro', service='Google AI Studio' max_output_tokens=2048)\n",
            "2\n",
            "Model response: 2\n",
            "runtime: 0.9978013038635254\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='Gemini', model_version='gemini-1.0-pro-001', service='Google Cloud' max_output_tokens=2048, temperature=0.8, top_k=40, top_p=1)\n",
            "Model response: 3\n",
            "runtime: 0.6266744136810303\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-3.5-turbo', service='Open AI' temperature=1.0)\n",
            "Model response: 3\n",
            "runtime: 0.38932204246520996\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-4-turbo-preview', service='Open AI' temperature=1.0)\n",
            "Model response: 3\n",
            "runtime: 0.5470700263977051\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-4', service='Open AI' temperature=1.0)\n",
            "Model response: 3\n",
            "runtime: 0.7345173358917236\n",
            "Evaluation passed.\n",
            "\n",
            "**********************************\n",
            "Evaluation #3\n",
            "Evaluation description: World facts\n",
            "Evaluation prompt: How tall is Mount Everest (rounded to the nearest meter)? Answer only with a number.\n",
            "Expected response: 8849\n",
            "Evaluation type: perfect_exact_match\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-haiku-20240307', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: 8,849\n",
            "runtime: 0.7426855564117432\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-sonnet-20240229', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: 8849\n",
            "runtime: 0.9666965007781982\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-opus-20240229', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: 8849\n",
            "runtime: 1.4651634693145752\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='Gemini', model_version='gemini-1.0-pro', service='Google AI Studio' max_output_tokens=2048)\n",
            "8848\n",
            "Model response: 8848\n",
            "runtime: 1.33128023147583\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='Gemini', model_version='gemini-1.0-pro-001', service='Google Cloud' max_output_tokens=2048, temperature=0.8, top_k=40, top_p=1)\n",
            "Model response: 8848\n",
            "runtime: 0.7831928730010986\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-3.5-turbo', service='Open AI' temperature=1.0)\n",
            "Model response: 8849 meters\n",
            "runtime: 0.7018680572509766\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-4-turbo-preview', service='Open AI' temperature=1.0)\n",
            "Model response: 8849\n",
            "runtime: 1.5269711017608643\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-4', service='Open AI' temperature=1.0)\n",
            "Model response: 8849\n",
            "runtime: 1.0862159729003906\n",
            "Evaluation passed.\n",
            "\n",
            "**********************************\n",
            "Evaluation #4\n",
            "Evaluation description: Historical facts\n",
            "Evaluation prompt: What century did the Dodo go extinct? Answer with just the century.\n",
            "Expected response: 17th\n",
            "Evaluation type: case_insensitive_match\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-haiku-20240307', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: 17th\n",
            "runtime: 0.7385978698730469\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-sonnet-20240229', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: 17th\n",
            "runtime: 0.7502965927124023\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-opus-20240229', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: 17th century.\n",
            "runtime: 1.745966911315918\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='Gemini', model_version='gemini-1.0-pro', service='Google AI Studio' max_output_tokens=2048)\n",
            "17th century\n",
            "Model response: 17th century\n",
            "runtime: 1.023796558380127\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='Gemini', model_version='gemini-1.0-pro-001', service='Google Cloud' max_output_tokens=2048, temperature=0.8, top_k=40, top_p=1)\n",
            "Model response: 17th\n",
            "runtime: 0.6570546627044678\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-3.5-turbo', service='Open AI' temperature=1.0)\n",
            "Model response: 17th century\n",
            "runtime: 0.3786745071411133\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-4-turbo-preview', service='Open AI' temperature=1.0)\n",
            "Model response: 17th century\n",
            "runtime: 0.6037042140960693\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-4', service='Open AI' temperature=1.0)\n",
            "Model response: 17th century\n",
            "runtime: 1.3427526950836182\n",
            "Evaluation failed!\n",
            "\n",
            "**********************************\n",
            "Evaluation #5\n",
            "Evaluation description: Historical facts\n",
            "Evaluation prompt: Who was the president of the United States in 2003? Answer with just the name please.\n",
            "Expected response: George W. Bush\n",
            "Evaluation type: case_insensitive_match\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-haiku-20240307', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: George W. Bush.\n",
            "runtime: 0.6544442176818848\n",
            "Evaluation failed!\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-sonnet-20240229', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: George W. Bush\n",
            "runtime: 0.7442922592163086\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-opus-20240229', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: George W. Bush\n",
            "runtime: 1.9191923141479492\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='Gemini', model_version='gemini-1.0-pro', service='Google AI Studio' max_output_tokens=2048)\n",
            "George W. Bush\n",
            "Model response: George W. Bush\n",
            "runtime: 1.2296853065490723\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='Gemini', model_version='gemini-1.0-pro-001', service='Google Cloud' max_output_tokens=2048, temperature=0.8, top_k=40, top_p=1)\n",
            "Model response: George W. Bush\n",
            "runtime: 0.813788890838623\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-3.5-turbo', service='Open AI' temperature=1.0)\n",
            "Model response: George W. Bush\n",
            "runtime: 0.3475806713104248\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-4-turbo-preview', service='Open AI' temperature=1.0)\n",
            "Model response: George W. Bush\n",
            "runtime: 0.6639492511749268\n",
            "Evaluation passed.\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-4', service='Open AI' temperature=1.0)\n",
            "Model response: George W. Bush\n",
            "runtime: 0.49544405937194824\n",
            "Evaluation passed.\n",
            "\n",
            "**********************************\n",
            "Evaluation #6\n",
            "Evaluation description: Article summary\n",
            "Evaluation prompt: Write a two sentence summary of this article: Stephen Gary Wozniak (/ˈwɒzniæk/; born August 11, 1950), also known by his nickname \"Woz\", is an American electrical engineer, computer programmer, philanthropist, and inventor. In 1976, he co-founded Apple Computer with his early business partner Steve Jobs. Through his work at Apple in the 1970s and 1980s, he is widely recognized as one of the most prominent pioneers of the personal computer revolution. In 1975, Wozniak started developing the Apple I: 150  into the computer that launched Apple when he and Jobs first began marketing it the following year. He primarily designed the Apple II, introduced in 1977, known as one of the first highly successful mass-produced microcomputers, while Jobs oversaw the development of its foam-molded plastic case and early Apple employee Rod Holt developed its switching power supply. With human–computer interface expert Jef Raskin, Wozniak had a major influence over the initial development of the origina\n",
            "Expected response: Stephen Wozniak, also known as \"Woz,\" is an American pioneer of the personal computer revolution, co-founding Apple Computer with Steve Jobs in 1976. From his work developing the Apple I and Apple II, he is widely recognized as one of the most prominent pioneers of the personal computer revolution.\n",
            "Evaluation type: rougeL\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-haiku-20240307', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: Here is a two-sentence summary:\n",
            "\n",
            "Steve Wozniak is an American engineer, programmer, and inventor who co-founded Apple Computer in 1976 and is widely recognized as a pioneer of the personal computer revolution. After leaving Apple in 1985, Wozniak has continued to pursue various business and philanthropic ventures, focusing on technology in education and other areas.\n",
            "runtime: 1.6234285831451416\n",
            "{'rougeL': Score(precision=0.3684210526315789, recall=0.42, fmeasure=0.3925233644859813)}\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-sonnet-20240229', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: Here is a two sentence summary:\n",
            "\n",
            "Stephen Wozniak is an American electrical engineer and inventor who co-founded Apple Computer with Steve Jobs in 1976 and played a pivotal role in the personal computer revolution. He designed the Apple I and Apple II computers which were hugely successful, and also had major influence on the early development of the Macintosh before leaving Apple in 1985.\n",
            "runtime: 2.8980751037597656\n",
            "{'rougeL': Score(precision=0.35384615384615387, recall=0.46, fmeasure=0.4)}\n",
            "---\n",
            "Model(model_family='Claude', model_version='claude-3-opus-20240229', service='Anthropic' max_tokens=4096, temperature=1.0)\n",
            "Model response: Stephen Wozniak, also known as \"Woz,\" is an American inventor and computer programmer who co-founded Apple Computer with Steve Jobs in 1976. He is widely recognized as a pioneer of the personal computer revolution, having developed the Apple I and primarily designed the highly successful Apple II, and he also had a major influence on the initial development of the original Apple Macintosh.\n",
            "runtime: 6.736963748931885\n",
            "{'rougeL': Score(precision=0.46875, recall=0.6, fmeasure=0.5263157894736842)}\n",
            "---\n",
            "Model(model_family='Gemini', model_version='gemini-1.0-pro', service='Google AI Studio' max_output_tokens=2048)\n",
            "Steve Wozniak, an electrical engineer and philanthropist, co-founded Apple Computer in 1976 with Steve Jobs and played a pivotal role in the personal computer revolution, particularly with the design of the Apple I and Apple II. After leaving Apple in 1985, Wozniak pursued various business and philanthropic ventures, including founding CL 9 and focusing on technology education.\n",
            "Model response: Steve Wozniak, an electrical engineer and philanthropist, co-founded Apple Computer in 1976 with Steve Jobs and played a pivotal role in the personal computer revolution, particularly with the design of the Apple I and Apple II. After leaving Apple in 1985, Wozniak pursued various business and philanthropic ventures, including founding CL 9 and focusing on technology education.\n",
            "runtime: 2.3727548122406006\n",
            "{'rougeL': Score(precision=0.27586206896551724, recall=0.32, fmeasure=0.29629629629629634)}\n",
            "---\n",
            "Model(model_family='Gemini', model_version='gemini-1.0-pro-001', service='Google Cloud' max_output_tokens=2048, temperature=0.8, top_k=40, top_p=1)\n",
            "Model response: Stephen Gary Wozniak, known as \"Woz,\" is an American pioneer in computer technology, having co-founded Apple Computer with Steve Jobs and designing the Apple II, one of the first successful personal computers. After leaving Apple in 1985, Wozniak continued to pursue entrepreneurial and philanthropic ventures in technology and education, while remaining an honorary employee of Apple.\n",
            "runtime: 1.2169690132141113\n",
            "{'rougeL': Score(precision=0.43859649122807015, recall=0.5, fmeasure=0.46728971962616817)}\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-3.5-turbo', service='Open AI' temperature=1.0)\n",
            "Model response: Stephen Wozniak, co-founder of Apple Computer with Steve Jobs, is an influential figure in the personal computer revolution of the 1970s and 1980s. After leaving Apple in 1985, Wozniak founded other businesses and focused on philanthropic endeavors, remaining a ceremonial employee of Apple and funding entrepreneurial efforts in various industries.\n",
            "runtime: 1.2517964839935303\n",
            "{'rougeL': Score(precision=0.2549019607843137, recall=0.26, fmeasure=0.25742574257425743)}\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-4-turbo-preview', service='Open AI' temperature=1.0)\n",
            "Model response: Stephen Gary Wozniak, known as \"Woz,\" is a co-founder of Apple Computer alongside Steve Jobs and a key figure in the personal computer revolution, with notable contributions including the development of the Apple I and Apple II computers in the late 1970s. After leaving Apple in 1985, Wozniak has been involved in various technology and philanthropic efforts, including creating the first programmable universal remote and supporting technology education, while maintaining a ceremonial role at Apple.\n",
            "runtime: 4.8477983474731445\n",
            "{'rougeL': Score(precision=0.27631578947368424, recall=0.42, fmeasure=0.33333333333333337)}\n",
            "---\n",
            "Model(model_family='GPT', model_version='gpt-4', service='Open AI' temperature=1.0)\n",
            "Model response: Stephen Gary Wozniak, also known as \"Woz\", co-founded Apple Computers with Steve Jobs in 1976 and played a key role in the personal computer revolution of the 1970s and 1980s, primarily designing the Apple II and contributing to the original Apple Macintosh concepts. After leaving Apple in 1985, he founded several other businesses and philanthropic ventures, including creating the first programmable universal remote, and continues to be involved in various tech-related endeavors, such as GPS, flash memory, and technical education.\n",
            "runtime: 5.614061594009399\n",
            "{'rougeL': Score(precision=0.25609756097560976, recall=0.42, fmeasure=0.31818181818181823)}\n",
            "\n",
            "Evaluations complete.\n",
            "**********************************\n",
            "Execution summary:\n",
            "Total runtime: 65.56242179870605\n",
            "\n",
            "Models: 8\n",
            "Evals: 6\n",
            "Total Evals: 48\n",
            "Passed Evals: 26\n",
            "Failed Evals: 14\n",
            "Other Evals: 8\n",
            "\n",
            "Evaluation matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "<thead>\n",
              "<tr style=\"text-align: right;\">\n",
              "<th></th>\n",
              "<th>claude-3-haiku-20240307 (Anthropic)</th>\n",
              "<th>claude-3-sonnet-20240229 (Anthropic)</th>\n",
              "<th>claude-3-opus-20240229 (Anthropic)</th>\n",
              "<th>gemini-1.0-pro (Google AI Studio)</th>\n",
              "<th>gemini-1.0-pro-001 (Google Cloud)</th>\n",
              "<th>gpt-3.5-turbo (Open AI)</th>\n",
              "<th>gpt-4-turbo-preview (Open AI)</th>\n",
              "<th>gpt-4 (Open AI)</th>\n",
              "<th>Totals</th>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr>\n",
              "<th>1: Basic math</th>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: red\">0.0</td>\n",
              "<td style=\"background-color: red\">0.000000</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: green\">1.00000</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: red\">0.000000</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td>5.000000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<th>2: Basic stats</th>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: green\">1.0</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: red\">0.000000</td>\n",
              "<td style=\"background-color: green\">1.00000</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td>7.000000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<th>3: World facts</th>\n",
              "<td style=\"background-color: red\">0.000000</td>\n",
              "<td style=\"background-color: green\">1.0</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: red\">0.000000</td>\n",
              "<td style=\"background-color: red\">0.00000</td>\n",
              "<td style=\"background-color: red\">0.000000</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td>4.000000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<th>4: Historical facts</th>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: green\">1.0</td>\n",
              "<td style=\"background-color: red\">0.000000</td>\n",
              "<td style=\"background-color: red\">0.000000</td>\n",
              "<td style=\"background-color: green\">1.00000</td>\n",
              "<td style=\"background-color: red\">0.000000</td>\n",
              "<td style=\"background-color: red\">0.000000</td>\n",
              "<td style=\"background-color: red\">0.000000</td>\n",
              "<td>3.000000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<th>5: Historical facts</th>\n",
              "<td style=\"background-color: red\">0.000000</td>\n",
              "<td style=\"background-color: green\">1.0</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: green\">1.00000</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td style=\"background-color: green\">1.000000</td>\n",
              "<td>7.000000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<th>6: Article summary</th>\n",
              "<td>0.392523</td>\n",
              "<td>0.4</td>\n",
              "<td>0.526316</td>\n",
              "<td>0.296296</td>\n",
              "<td>0.46729</td>\n",
              "<td>0.257426</td>\n",
              "<td>0.333333</td>\n",
              "<td>0.318182</td>\n",
              "<td>2.991366</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<th>Totals</th>\n",
              "<td>3.392523</td>\n",
              "<td>4.4</td>\n",
              "<td>3.526316</td>\n",
              "<td>2.296296</td>\n",
              "<td>4.46729</td>\n",
              "<td>3.257426</td>\n",
              "<td>3.333333</td>\n",
              "<td>4.318182</td>\n",
              "<td>28.991366</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Runtime matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claude-3-haiku-20240307 (Anthropic)</th>\n",
              "      <th>claude-3-sonnet-20240229 (Anthropic)</th>\n",
              "      <th>claude-3-opus-20240229 (Anthropic)</th>\n",
              "      <th>gemini-1.0-pro (Google AI Studio)</th>\n",
              "      <th>gemini-1.0-pro-001 (Google Cloud)</th>\n",
              "      <th>gpt-3.5-turbo (Open AI)</th>\n",
              "      <th>gpt-4-turbo-preview (Open AI)</th>\n",
              "      <th>gpt-4 (Open AI)</th>\n",
              "      <th>Totals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1: Basic math</th>\n",
              "      <td>0.784676</td>\n",
              "      <td>0.691222</td>\n",
              "      <td>4.338898</td>\n",
              "      <td>1.345348</td>\n",
              "      <td>0.715232</td>\n",
              "      <td>0.320655</td>\n",
              "      <td>1.080130</td>\n",
              "      <td>0.696294</td>\n",
              "      <td>9.972455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2: Basic stats</th>\n",
              "      <td>0.603246</td>\n",
              "      <td>0.655983</td>\n",
              "      <td>1.682108</td>\n",
              "      <td>0.997801</td>\n",
              "      <td>0.626674</td>\n",
              "      <td>0.389322</td>\n",
              "      <td>0.547070</td>\n",
              "      <td>0.734517</td>\n",
              "      <td>6.236722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3: World facts</th>\n",
              "      <td>0.742686</td>\n",
              "      <td>0.966697</td>\n",
              "      <td>1.465163</td>\n",
              "      <td>1.331280</td>\n",
              "      <td>0.783193</td>\n",
              "      <td>0.701868</td>\n",
              "      <td>1.526971</td>\n",
              "      <td>1.086216</td>\n",
              "      <td>8.604074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4: Historical facts</th>\n",
              "      <td>0.738598</td>\n",
              "      <td>0.750297</td>\n",
              "      <td>1.745967</td>\n",
              "      <td>1.023797</td>\n",
              "      <td>0.657055</td>\n",
              "      <td>0.378675</td>\n",
              "      <td>0.603704</td>\n",
              "      <td>1.342753</td>\n",
              "      <td>7.240844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5: Historical facts</th>\n",
              "      <td>0.654444</td>\n",
              "      <td>0.744292</td>\n",
              "      <td>1.919192</td>\n",
              "      <td>1.229685</td>\n",
              "      <td>0.813789</td>\n",
              "      <td>0.347581</td>\n",
              "      <td>0.663949</td>\n",
              "      <td>0.495444</td>\n",
              "      <td>6.868377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6: Article summary</th>\n",
              "      <td>1.623429</td>\n",
              "      <td>2.898075</td>\n",
              "      <td>6.736964</td>\n",
              "      <td>2.372755</td>\n",
              "      <td>1.216969</td>\n",
              "      <td>1.251796</td>\n",
              "      <td>4.847798</td>\n",
              "      <td>5.614062</td>\n",
              "      <td>26.561848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Totals</th>\n",
              "      <td>5.147078</td>\n",
              "      <td>6.706566</td>\n",
              "      <td>17.888293</td>\n",
              "      <td>8.300666</td>\n",
              "      <td>4.812912</td>\n",
              "      <td>3.389896</td>\n",
              "      <td>9.269623</td>\n",
              "      <td>9.969285</td>\n",
              "      <td>65.484319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}